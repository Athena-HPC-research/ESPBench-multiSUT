\chapter{Setup and Execution of ESPBench -\/ Detailed Instructions}
\hypertarget{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed}{}\label{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed}\index{Setup and Execution of ESPBench -\/ Detailed Instructions@{Setup and Execution of ESPBench -\/ Detailed Instructions}}
\label{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md0}%
\Hypertarget{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md0}%
 In the following, we explain the setup of the experimental evaluation presented in the paper {\itshape ESPBench\+: The Enterprise Stream Processing Benchmark} published at ICPE 2021.\hypertarget{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md1}{}\doxysubsection{\texorpdfstring{Server Characteristics}{Server Characteristics}}\label{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md1}
We used 8 virtual machines for the evaluation, each one equipped with {\bfseries{Ubuntu 18.\+04 LTS}} as OS. Their purpose is described in the following\+:
\begin{DoxyItemize}
\item \#1\+: only used for invoking the ansible script/starting the benchmark process
\item \#2-\/4\+: Apache Kafka cluster\+:
\end{DoxyItemize}




\begin{DoxyItemize}
\item \#5-\/8\+: System Under Test (SUT) nodes
\begin{DoxyItemize}
\item \#5-\/7\+: DSPS nodes (Apache Spark, Apache Flink, Hazelcast Jet)
\item \#8\+: DBMS (Postgre\+SQL) node
\end{DoxyItemize}
\end{DoxyItemize}

\hypertarget{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md2}{}\doxysubsection{\texorpdfstring{Server Setup}{Server Setup}}\label{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md2}
Please find instructions for setting up the servers in the following\+:\hypertarget{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md3}{}\doxysubsubsection{\texorpdfstring{1. General}{1. General}}\label{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md3}
\hypertarget{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md4}{}\doxyparagraph{\texorpdfstring{    a. Create a user $<$tt$>$benchmarker$<$/tt$>$ on all involved machines that has sudo access}{    a. Create a user <tt>benchmarker</tt> on all involved machines that has sudo access}}\label{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md4}
{\ttfamily sudo adduser benchmarker}

In case you get the error {\ttfamily passwd\+: Module is unknown}, execute the following\+: {\ttfamily sudo apt install libpam-\/cracklib} \hypertarget{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md5}{}\doxyparagraph{\texorpdfstring{    b. Ensure that this user can connect to all machines via ssh w/o password, e.\+g., through adding the ssh public key to the $<$tt$>$authorized\+\_\+keys$<$/tt$>$ files}{    b. Ensure that this user can connect to all machines via ssh w/o password, e.g., through adding the ssh public key to the <tt>authorized\_keys</tt> files}}\label{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md5}

\begin{DoxyItemize}
\item Connect to the first server and generate ssh keys through executing the following command as user {\ttfamily benchmarker}\+: {\ttfamily ssh-\/keygen}
\item Append the content of {\ttfamily \texorpdfstring{$\sim$}{\string~}/.ssh/id\+\_\+rsa.\+pub} to the file {\ttfamily /home/benchmarker/.ssh/authorized\+\_\+keys} on all servers
\item Repeat the upper two steps for all servers
\item Verify that you are now able to connect via ssh from any server to any other server w/o the need to enter
\item On the first server, create the directory {\ttfamily Benchmarks} in the home directory of the user {\ttfamily benchmarker} and clone the repository into this folder\+: {\ttfamily git clone \href{https://github.com/guenter-hesse/ESPBench.git}{\texttt{ https\+://github.\+com/guenter-\/hesse/\+ESPBench.\+git}}}
\item Change to the cloned repository directory and build the project using {\ttfamily sbt assembly} -\/ if necessary, install {\ttfamily scala} and {\ttfamily sbt} first according to \href{https://www.scala-lang.org/download/}{\texttt{ https\+://www.\+scala-\/lang.\+org/download/}} and \href{https://www.scala-sbt.org/1.x/docs/Installing-sbt-on-Linux.html}{\texttt{ https\+://www.\+scala-\/sbt.\+org/1.\+x/docs/\+Installing-\/sbt-\/on-\/\+Linux.\+html}} , respectively.
\end{DoxyItemize}\hypertarget{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md6}{}\doxysubsubsection{\texorpdfstring{2. Apache Kafka}{2. Apache Kafka}}\label{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md6}

\begin{DoxyItemize}
\item Connect to the Apache Kafka servers and execute the following steps on each of the three Apache Kafka servers to install Apache Zoo\+Keeper™ and Apache Kafka
\item Install and configure Apache Zoo\+Keeper™ as described in \href{https://linuxconfig.org/how-to-install-and-configure-zookeeper-in-ubuntu-18-04}{\texttt{ https\+://linuxconfig.\+org/how-\/to-\/install-\/and-\/configure-\/zookeeper-\/in-\/ubuntu-\/18-\/04}}
\item Download Apache Kafka from \href{https://kafka.apache.org/downloads}{\texttt{ https\+://kafka.\+apache.\+org/downloads}}, e.\+g., via {\ttfamily wget \href{https://archive.apache.org/dist/kafka/2.3.0/kafka_2.11-2.3.0.tgz}{\texttt{ https\+://archive.\+apache.\+org/dist/kafka/2.\+3.\+0/kafka\+\_\+2.\+11-\/2.\+3.\+0.\+tgz}}}
\item Unpack the downloaded file and move it to the {\ttfamily /opt/} directory\+:
\begin{DoxyItemize}
\item {\ttfamily tar -\/xzf kafka\+\_\+2.\+11-\/2.\+3.\+0.\+tgz}
\item {\ttfamily mv kafka\+\_\+2.\+11-\/2.\+3.\+0 kafka \&\& mv kafka /opt/} ~\newline

\item Copy the Apache Kafka configuration files from the benchmark repository directory {\ttfamily tools/configurations} to {\ttfamily /opt/kafka/config/}
\end{DoxyItemize}
\item Make Apache Kafka a service\+:
\begin{DoxyItemize}
\item Run {\ttfamily sudo apt install policykit-\/1}
\item Copy {\ttfamily tools/configuration/kafka/etc/init.\+d/kafka} from the benchmark repository to {\ttfamily /etc/init.d/} on the Apache Kafka servers
\item Run {\ttfamily update-\/rc.\+d kafka defaults}
\end{DoxyItemize}
\end{DoxyItemize}\hypertarget{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md7}{}\doxysubsubsection{\texorpdfstring{3. System Under Test}{3. System Under Test}}\label{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md7}
\hypertarget{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md8}{}\doxyparagraph{\texorpdfstring{    a. DBMS -\/ Postgre\+SQL}{    a. DBMS - PostgreSQL}}\label{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md8}
Install {\ttfamily Postgre\+SQL} on the DBMS server (you can use another DBMS, however, that requires some adaptions in the tools), e.\+g., via {\ttfamily sudo apt install postgresql-\/9.\+6}\hypertarget{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md9}{}\doxyparagraph{\texorpdfstring{    a. DSPS}{    a. DSPS}}\label{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md9}
The steps for installing the DSPS are very similar to those above for installing Apache Kafka.
\begin{DoxyItemize}
\item Apache Flink
\begin{DoxyItemize}
\item Go to the DSPS servers and download Apache Flink from \href{https://flink.apache.org/downloads.html}{\texttt{ https\+://flink.\+apache.\+org/downloads.\+html}}
\item Unpack the downloaded archive using the {\ttfamily tar -\/xzf} command
\item (Re)name the directory {\ttfamily flink} and move it to {\ttfamily /opt/}
\item Copy the Apache Flink configuration files from the benchmark repository directory {\ttfamily tools/configurations} to {\ttfamily /opt/flink/conf/}
\end{DoxyItemize}
\item Apache Spark Streaming
\begin{DoxyItemize}
\item Go to the DSPS servers and download Apache Flink from \href{https://flink.apache.org/downloads.html}{\texttt{ https\+://flink.\+apache.\+org/downloads.\+html}}
\item Unpack the downloaded archive using the {\ttfamily tar -\/xzf} command
\item (Re)name the directory {\ttfamily flink} and move it to {\ttfamily /opt/}
\item Copy the Apache Flink configuration files from the benchmark repository directory {\ttfamily tools/configurations} to {\ttfamily /opt/flink/conf/}
\end{DoxyItemize}
\item Hazelcast Jet
\begin{DoxyItemize}
\item Go to the DSPS servers and download Hazelcast Jet from \href{https://jet-start.sh/download}{\texttt{ https\+://jet-\/start.\+sh/download}}
\item Unpack the downloaded archive using the {\ttfamily tar -\/xzf} command
\item (Re)name the directory {\ttfamily hazelcast-\/jet} and move it to {\ttfamily /opt/}
\item Copy the Hazelcast Jet configuration files from the benchmark repository directory {\ttfamily tools/configurations} to {\ttfamily /opt/spark/config/}
\end{DoxyItemize}
\end{DoxyItemize}\hypertarget{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md10}{}\doxysubsection{\texorpdfstring{Benchmark Execution}{Benchmark Execution}}\label{md_ESPBench-multiSUT_2docs_2ESPBenchSetupAndExecutionDetailed_autotoc_md10}
There are multiple configuration files provided by ESPBench, which need to be adapted according to specific environments and wishes. The parts that require adaptions in the ESPBench repository, which is cloned to the first node, are explained in the following\+:

\doxysubparagraph*{tools/commons/commons.\+conf}


\begin{DoxyItemize}
\item Define the Apache Kafka topic prefix and the benchmark run number, which will have an impact on the Apache Kafka topic names that are going to be created by the ansible scripts
\item Define the query you want to execute (config name for each query is included in the file)
\item Define the sending interval, which determines the pause between sending two records -\/ a pause of, e.\+g., 1,000,000ns would result in an input rate of 1,000 records/s
\item Define the benchmark duration
\item Define the Apache Kafka bootstrap servers and zookeeper servers
\end{DoxyItemize}

\doxysubparagraph*{tools/datasender}


\begin{DoxyItemize}
\item Input data is taken from DEBS 2012 Grand Challenge, which can be downloaded from \href{ftp://ftp.mi.fu-berlin.de/pub/debs2012/}{\texttt{ ftp\+://ftp.\+mi.\+fu-\/berlin.\+de/pub/debs2012/}}
\item This data file needs to be converted using the {\ttfamily dos2unix} command, and duplicated, so that there are two input files.
\item The two files need to be extended by a machine ID using the following commands (adapt file names)\+:
\begin{DoxyItemize}
\item First file\+: `awk \textquotesingle{}BEGIN \{ FS = OFS = "{}\textbackslash{}t"{} \} \{ \$(NF+1) = 1; print \$0 \}' input1.\+csv \texorpdfstring{$>$}{>} output1.\+csv{\ttfamily }
\item {\ttfamily Second file\+:}awk \textquotesingle{}BEGIN \{ FS = OFS = "{}\textbackslash{}t"{} \} \{ \$(NF+1) = 2; print \$0 \}\textquotesingle{} input2.\+csv \texorpdfstring{$>$}{>} output2.\+csv{\ttfamily }
\end{DoxyItemize}
\item {\ttfamily A third input file is}production\+\_\+times.\+csv{\ttfamily , which is generated by the TPC-\/C data generator that is part of this project.}
\item {\ttfamily The file}datasender.\+conf{\ttfamily contains Apache Kafka producer configs and the location of the input data files.}
\item {\ttfamily The file}src/main/resources/application.\+conf\`{} needs the correct DBMS configuration.
\end{DoxyItemize}

\doxysubparagraph*{tools/tpc-\/c\+\_\+gen}

The {\ttfamily tpc-\/c.\+properties} file contains the default setting WRT the number of warehouses and the data output directory. Changes of the output directory require according adaptions in ansible scripts.

\doxysubparagraph*{tools/validator}

The file {\ttfamily src/main/resources/application.\+conf} needs the correct DBMS configuration.

\doxysubparagraph*{Example Implementation -\/ implementation/beam}

If you want to use the example implementation, you need to adapt at least two files accordingly\+:
\begin{DoxyItemize}
\item {\ttfamily implementation/beam/src/main/resources/beam.\+properties}
\item The {\ttfamily beam\+Runner} variable in {\ttfamily build.\+sbt}
\end{DoxyItemize}

\doxysubparagraph*{tools/configuration}


\begin{DoxyItemize}
\item Adapt the {\ttfamily group\+\_\+vars/all} files if needed
\item The directories {\ttfamily plays} and {\ttfamily roles} contain several ansible files, which can be adapted if needed.
\item The {\ttfamily hosts} file needs to be edited, i.\+e, the servers\textquotesingle{} IP addresses need to be entered
\item To finally run the benchmark after doing all the steps above
\begin{DoxyItemize}
\item Change to the {\ttfamily tools/configuration} directory
\item Start the benchmark process via {\ttfamily ansible-\/playbook -\/vvvv plays/benchmark-\/runner-\/beam.\+yml} for if you want to use the example implementations provided by ESPBench. The number of {\ttfamily v} define the level of verbosity 
\end{DoxyItemize}
\end{DoxyItemize}