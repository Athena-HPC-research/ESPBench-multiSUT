<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ESPBench-multiSUT: Setup and Execution of ESPBench - Detailed Instructions</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">ESPBench-multiSUT
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

</div><!-- top -->
<div><div class="header">
  <div class="headertitle"><div class="title">Setup and Execution of ESPBench - Detailed Instructions</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="autotoc_md0"></a> In the following, we explain the setup of the experimental evaluation presented in the paper <em>ESPBench: The Enterprise Stream Processing Benchmark</em> published at ICPE 2021.</p>
<h2><a class="anchor" id="autotoc_md1"></a>
Server Characteristics</h2>
<p>We used 8 virtual machines for the evaluation, each one equipped with <b>Ubuntu 18.04 LTS</b> as OS. Their purpose is described in the following:</p><ul>
<li>#1: only used for invoking the ansible script/starting the benchmark process</li>
<li>#2-4: Apache Kafka cluster:</li>
</ul>
<p><img src="img/KafkaCluster.png" alt="Kafka cluster" class="inline"/></p>
<ul>
<li>#5-8: System Under Test (SUT) nodes<ul>
<li>#5-7: DSPS nodes (Apache Spark, Apache Flink, Hazelcast Jet)</li>
<li>#8: DBMS (PostgreSQL) node</li>
</ul>
</li>
</ul>
<p><img src="img/SUTCluster.png" alt="SUT Cluster" class="inline"/></p>
<h2><a class="anchor" id="autotoc_md2"></a>
Server Setup</h2>
<p>Please find instructions for setting up the servers in the following:</p>
<h3><a class="anchor" id="autotoc_md3"></a>
1. General</h3>
<h4><a class="anchor" id="autotoc_md4"></a>
    a. Create a user &lt;tt&gt;benchmarker&lt;/tt&gt; on all involved machines that has sudo access</h4>
<p><code>sudo adduser benchmarker</code></p>
<p>In case you get the error <code>passwd: Module is unknown</code>, execute the following: <code>sudo apt install libpam-cracklib</code> </p>
<h4><a class="anchor" id="autotoc_md5"></a>
    b. Ensure that this user can connect to all machines via ssh w/o password, e.g., through adding the ssh public key to the &lt;tt&gt;authorized_keys&lt;/tt&gt; files</h4>
<ul>
<li>Connect to the first server and generate ssh keys through executing the following command as user <code>benchmarker</code>: <code>ssh-keygen</code></li>
<li>Append the content of <code>~/.ssh/id_rsa.pub</code> to the file <code>/home/benchmarker/.ssh/authorized_keys</code> on all servers</li>
<li>Repeat the upper two steps for all servers</li>
<li>Verify that you are now able to connect via ssh from any server to any other server w/o the need to enter</li>
<li>On the first server, create the directory <code>Benchmarks</code> in the home directory of the user <code>benchmarker</code> and clone the repository into this folder: <code>git clone <a href="https://github.com/guenter-hesse/ESPBench.git">https://github.com/guenter-hesse/ESPBench.git</a></code></li>
<li>Change to the cloned repository directory and build the project using <code>sbt assembly</code> - if necessary, install <code>scala</code> and <code>sbt</code> first according to <a href="https://www.scala-lang.org/download/">https://www.scala-lang.org/download/</a> and <a href="https://www.scala-sbt.org/1.x/docs/Installing-sbt-on-Linux.html">https://www.scala-sbt.org/1.x/docs/Installing-sbt-on-Linux.html</a> , respectively.</li>
</ul>
<h3><a class="anchor" id="autotoc_md6"></a>
2. Apache Kafka</h3>
<ul>
<li>Connect to the Apache Kafka servers and execute the following steps on each of the three Apache Kafka servers to install Apache ZooKeeper™ and Apache Kafka</li>
<li>Install and configure Apache ZooKeeper™ as described in <a href="https://linuxconfig.org/how-to-install-and-configure-zookeeper-in-ubuntu-18-04">https://linuxconfig.org/how-to-install-and-configure-zookeeper-in-ubuntu-18-04</a></li>
<li>Download Apache Kafka from <a href="https://kafka.apache.org/downloads">https://kafka.apache.org/downloads</a>, e.g., via <code>wget <a href="https://archive.apache.org/dist/kafka/2.3.0/kafka_2.11-2.3.0.tgz">https://archive.apache.org/dist/kafka/2.3.0/kafka_2.11-2.3.0.tgz</a></code></li>
<li>Unpack the downloaded file and move it to the <code>/opt/</code> directory:<ul>
<li><code>tar -xzf kafka_2.11-2.3.0.tgz</code></li>
<li><code>mv kafka_2.11-2.3.0 kafka &amp;&amp; mv kafka /opt/</code> <br  />
</li>
<li>Copy the Apache Kafka configuration files from the benchmark repository directory <code>tools/configurations</code> to <code>/opt/kafka/config/</code></li>
</ul>
</li>
<li>Make Apache Kafka a service:<ul>
<li>Run <code>sudo apt install policykit-1</code></li>
<li>Copy <code>tools/configuration/kafka/etc/init.d/kafka</code> from the benchmark repository to <code>/etc/init.d/</code> on the Apache Kafka servers</li>
<li>Run <code>update-rc.d kafka defaults</code></li>
</ul>
</li>
</ul>
<h3><a class="anchor" id="autotoc_md7"></a>
3. System Under Test</h3>
<h4><a class="anchor" id="autotoc_md8"></a>
    a. DBMS - PostgreSQL</h4>
<p>Install <code>PostgreSQL</code> on the DBMS server (you can use another DBMS, however, that requires some adaptions in the tools), e.g., via <code>sudo apt install postgresql-9.6</code></p>
<h4><a class="anchor" id="autotoc_md9"></a>
    a. DSPS</h4>
<p>The steps for installing the DSPS are very similar to those above for installing Apache Kafka.</p><ul>
<li>Apache Flink<ul>
<li>Go to the DSPS servers and download Apache Flink from <a href="https://flink.apache.org/downloads.html">https://flink.apache.org/downloads.html</a></li>
<li>Unpack the downloaded archive using the <code>tar -xzf</code> command</li>
<li>(Re)name the directory <code>flink</code> and move it to <code>/opt/</code></li>
<li>Copy the Apache Flink configuration files from the benchmark repository directory <code>tools/configurations</code> to <code>/opt/flink/conf/</code></li>
</ul>
</li>
<li>Apache Spark Streaming<ul>
<li>Go to the DSPS servers and download Apache Flink from <a href="https://flink.apache.org/downloads.html">https://flink.apache.org/downloads.html</a></li>
<li>Unpack the downloaded archive using the <code>tar -xzf</code> command</li>
<li>(Re)name the directory <code>flink</code> and move it to <code>/opt/</code></li>
<li>Copy the Apache Flink configuration files from the benchmark repository directory <code>tools/configurations</code> to <code>/opt/flink/conf/</code></li>
</ul>
</li>
<li>Hazelcast Jet<ul>
<li>Go to the DSPS servers and download Hazelcast Jet from <a href="https://jet-start.sh/download">https://jet-start.sh/download</a></li>
<li>Unpack the downloaded archive using the <code>tar -xzf</code> command</li>
<li>(Re)name the directory <code>hazelcast-jet</code> and move it to <code>/opt/</code></li>
<li>Copy the Hazelcast Jet configuration files from the benchmark repository directory <code>tools/configurations</code> to <code>/opt/spark/config/</code></li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="autotoc_md10"></a>
Benchmark Execution</h2>
<p>There are multiple configuration files provided by ESPBench, which need to be adapted according to specific environments and wishes. The parts that require adaptions in the ESPBench repository, which is cloned to the first node, are explained in the following:</p>
<h5>tools/commons/commons.conf</h5>
<ul>
<li>Define the Apache Kafka topic prefix and the benchmark run number, which will have an impact on the Apache Kafka topic names that are going to be created by the ansible scripts</li>
<li>Define the query you want to execute (config name for each query is included in the file)</li>
<li>Define the sending interval, which determines the pause between sending two records - a pause of, e.g., 1,000,000ns would result in an input rate of 1,000 records/s</li>
<li>Define the benchmark duration</li>
<li>Define the Apache Kafka bootstrap servers and zookeeper servers</li>
</ul>
<h5>tools/datasender</h5>
<ul>
<li>Input data is taken from DEBS 2012 Grand Challenge, which can be downloaded from <a href="ftp://ftp.mi.fu-berlin.de/pub/debs2012/">ftp://ftp.mi.fu-berlin.de/pub/debs2012/</a></li>
<li>This data file needs to be converted using the <code>dos2unix</code> command, and duplicated, so that there are two input files.</li>
<li>The two files need to be extended by a machine ID using the following commands (adapt file names):<ul>
<li>First file: &lsquo;awk 'BEGIN { FS = OFS = "\t" } { $(NF+1) = 1; print $0 }&rsquo; input1.csv &gt; output1.csv<code></code></li>
<li><code>Second file:</code>awk 'BEGIN { FS = OFS = "\t" } { $(NF+1) = 2; print $0 }' input2.csv &gt; output2.csv<code></code></li>
</ul>
</li>
<li><code>A third input file is</code>production_times.csv<code>, which is generated by the TPC-C data generator that is part of this project.</code></li>
<li><code>The file</code>datasender.conf<code>contains Apache Kafka producer configs and the location of the input data files.</code></li>
<li><code>The file</code>src/main/resources/application.conf` needs the correct DBMS configuration.</li>
</ul>
<h5>tools/tpc-c_gen</h5>
<p>The <code>tpc-c.properties</code> file contains the default setting WRT the number of warehouses and the data output directory. Changes of the output directory require according adaptions in ansible scripts.</p>
<h5>tools/validator</h5>
<p>The file <code>src/main/resources/application.conf</code> needs the correct DBMS configuration.</p>
<h5>Example Implementation - implementation/beam</h5>
<p>If you want to use the example implementation, you need to adapt at least two files accordingly:</p><ul>
<li><code>implementation/beam/src/main/resources/beam.properties</code></li>
<li>The <code>beamRunner</code> variable in <code>build.sbt</code></li>
</ul>
<h5>tools/configuration</h5>
<ul>
<li>Adapt the <code>group_vars/all</code> files if needed</li>
<li>The directories <code>plays</code> and <code>roles</code> contain several ansible files, which can be adapted if needed.</li>
<li>The <code>hosts</code> file needs to be edited, i.e, the servers' IP addresses need to be entered</li>
<li>To finally run the benchmark after doing all the steps above<ul>
<li>Change to the <code>tools/configuration</code> directory</li>
<li>Start the benchmark process via <code>ansible-playbook -vvvv plays/benchmark-runner-beam.yml</code> for if you want to use the example implementations provided by ESPBench. The number of <code>v</code> define the level of verbosity </li>
</ul>
</li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
